{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diXeCiY16yAj",
        "outputId": "d857b664-bb62-423e-afd9-93036b43b15b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.25)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas matplotlib seaborn scikit-learn tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional,LSTM, Dense\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from time import time\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, TimeDistributed, Conv1D, MaxPooling1D, Flatten"
      ],
      "metadata": {
        "id": "nPeIurlv7ebB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load data\n",
        "def load_data(features_dir, labels_dir):\n",
        "    feature_files = sorted([f for f in os.listdir(features_dir) if not f.startswith('.')])\n",
        "    label_files = sorted([f for f in os.listdir(labels_dir) if not f.startswith('.')])\n",
        "\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for feature_file, label_file in zip(feature_files, label_files):\n",
        "        feature_data = np.load(os.path.join(features_dir, feature_file))\n",
        "        label_data = np.load(os.path.join(labels_dir, label_file))\n",
        "\n",
        "        features.append(feature_data)\n",
        "        labels.append(label_data)\n",
        "\n",
        "    features = np.concatenate(features)\n",
        "    labels = np.concatenate(labels)\n",
        "\n",
        "    return features, labels\n"
      ],
      "metadata": {
        "id": "Zmb9cgY478se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data\n",
        "features_dir = '/content/drive/MyDrive/content/sensor'  # Update path as needed\n",
        "labels_dir = '/content/drive/MyDrive/content/target'     # Update path as needed\n",
        "features, labels = load_data(features_dir, labels_dir)\n",
        "\n",
        "# One-hot encode labels\n",
        "labels = to_categorical(labels, num_classes=12)\n",
        "\n",
        "for i in range(2320,2380):\n",
        "  print(features[i])\n",
        "  print(labels[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uGqxL5w8G4r",
        "outputId": "c586605c-d275-423f-9d76-7a1b8f209d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  25.490205   80.       -101.         24.13        0.          0.\n",
            "    1.         14.404297]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  25.490205   46.6      -122.         25.32        0.          0.\n",
            "    0.          8.789062]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 25.098048  20.7      -34.        26.15       0.         0.\n",
            "   0.         4.150391]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 21.568635  -6.5      -72.        27.22       0.         0.\n",
            "   0.         0.      ]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 18.039222 -20.8      -32.        27.38       0.         0.\n",
            "   0.        -2.929688]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 17.254908 -27.9      -19.        29.31       0.         0.\n",
            "   0.        -4.638672]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 17.254908 -28.6        0.        30.03       0.         0.\n",
            "   0.        -5.126953]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 16.470594 -27.6        1.        30.65       0.         0.\n",
            "   0.        -5.126953]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 15.294123 -27.1        0.        31.28       0.         0.\n",
            "   0.        -4.638672]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 15.294123 -28.5       -4.        31.75       0.         0.\n",
            "   0.        -4.638672]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 15.294123 -28.8       -3.        32.37       0.         0.\n",
            "   0.        -5.126953]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 14.901966 -30.5       -5.        32.64       0.         0.\n",
            "   0.        -5.371094]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 15.294123 -31.2       -3.        32.98       0.         0.\n",
            "   0.        -5.615234]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 15.68628  -32.2       -6.        33.25       0.         0.\n",
            "   0.        -5.615234]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 16.078437 -32.5        0.        33.62       0.         0.\n",
            "   0.        -6.103516]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 16.078437 -32.5        0.        33.85       0.         0.\n",
            "   0.        -5.859375]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 16.078437 -32.7        0.        34.49       0.         0.\n",
            "   0.        -6.103516]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 16.078437 -33.6       -7.        34.8        0.         0.\n",
            "   0.        -6.347656]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 15.68628  -34.6       -6.        35.28       0.         0.\n",
            "   0.        -6.347656]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 11.76471  -35.5        0.        35.61       0.         0.\n",
            "   0.        -6.591797]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  8.627454 -34.2       12.        35.97       0.         0.\n",
            "   0.        -6.835938]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  4.705884 -33.6       -2.        36.08       0.         0.\n",
            "   0.        -6.347656]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  3.92157  -34.4        0.        36.31       0.         0.\n",
            "   0.        -6.591797]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  2.745099 -34.4        0.        36.27       0.         0.\n",
            "   0.        -6.591797]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  2.745099 -34.4        1.        36.28       0.         0.\n",
            "   0.        -6.591797]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  3.529413 -34.4        1.        36.38       0.         0.\n",
            "   0.        -6.591797]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  6.274512 -33.8        0.        36.3        0.         0.\n",
            "   0.        -6.591797]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  6.274512 -34.        -1.        36.3        0.         0.\n",
            "   0.        -6.591797]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  7.058826 -35.6       -8.        36.51       0.         0.\n",
            "   0.        -6.591797]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  7.450983 -36.        -5.        36.83       0.         0.\n",
            "   0.        -6.591797]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  8.627454 -36.3        0.        36.5        0.         0.\n",
            "   0.        -6.591797]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 10.196082 -36.3        0.        36.67       0.         0.\n",
            "   0.        -6.835938]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 13.333338 -36.2        3.        36.91       0.         0.\n",
            "   0.        -6.835938]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 14.117652 -33.6        4.        37.         0.         0.\n",
            "   0.        -6.591797]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 15.294123 -30.4       21.        37.4        0.         0.\n",
            "   0.        -6.103516]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 16.470594 -22.5       25.        37.78       0.         0.\n",
            "   0.        -4.638672]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 16.470594 -13.4       24.        37.92       0.         0.\n",
            "   0.        -2.929688]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 17.254908 -10.1       14.        38.56       0.         0.\n",
            "   0.        -1.953125]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[17.254908  0.3      22.       38.95      0.        0.        0.\n",
            "  0.      ]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[17.254908  4.4      11.       39.54      0.        0.        0.\n",
            "  0.488281]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[17.254908  6.5       5.       40.02      0.        0.        0.\n",
            "  1.464844]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[17.254908  9.8      10.       40.23      0.        0.        0.\n",
            "  1.708984]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[17.647065 11.9      11.       40.66      0.        0.        0.\n",
            "  1.953125]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[17.647065 14.2       6.       41.05      0.        0.        0.\n",
            "  2.685547]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[17.254908 15.3       5.       41.47      0.        0.        0.\n",
            "  2.929688]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[17.254908 17.        0.       41.73      0.        0.        0.\n",
            "  3.417969]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[17.254908 17.6       1.       42.22      0.        0.        0.\n",
            "  3.662109]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[17.254908 17.9       0.       42.63      0.        0.        0.\n",
            "  3.662109]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[15.294123 18.3       2.       42.91      0.        0.        0.\n",
            "  3.662109]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 2.745099 19.3       0.       43.1       0.        0.        0.\n",
            "  3.90625 ]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 1.568628 20.1       7.       43.05      0.        0.        0.\n",
            "  3.90625 ]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 1.568628 21.7       3.       43.14      0.        0.        0.\n",
            "  4.394531]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 1.568628 21.9      -3.       42.89      0.        0.        0.\n",
            "  4.638672]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 1.568628 20.9      -8.       42.83      0.        0.        0.\n",
            "  4.394531]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  1.568628  12.9      -22.        42.8        0.         0.\n",
            "   0.         3.173828]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  3.529413   8.1      -11.        42.67       0.         0.\n",
            "   0.         1.708984]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  4.705884   5.6      -12.        42.67       0.         0.\n",
            "   0.         1.220703]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[  6.274512   0.2      -11.        42.56       0.         0.\n",
            "   0.         0.244141]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 6.274512 -1.2       3.       42.52      0.        0.        0.\n",
            "  0.      ]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 6.274512 -1.4       0.       42.48      0.        0.        0.\n",
            "  0.      ]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `labels` is a numpy array of shape (n_samples, 12) where each row is a one-hot encoded class label\n",
        "class_frequencies = np.sum(labels, axis=0)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=np.arange(12), y=class_frequencies)\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(np.arange(12))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "N9LLmnIV9i5y",
        "outputId": "bc3da040-9292-4885-fd40-84042e5e4e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert one-hot encoded labels back to categorical labels for stratification\n",
        "categorical_labels = np.argmax(labels, axis=1)\n",
        "\n",
        "# Split the dataset into training and testing sets with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, categorical_labels,\n",
        "    test_size=0.2,  # 20% of the data for testing\n",
        "    random_state=42,  # For reproducibility\n",
        "    stratify=categorical_labels  # Ensures proportional representation of each class\n",
        ")\n",
        "\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "\n",
        "\n",
        "# Convert categorical labels back to one-hot encoding for model training if needed\n",
        "y_train_one_hot = np.eye(12)[y_train]\n",
        "y_test_one_hot = np.eye(12)[y_test]\n",
        "\n",
        "# Now `X_train` and `X_test` are your features for training and testing,\n",
        "# and `y_train_one_hot` and `y_test_one_hot` are the corresponding one-hot encoded labels."
      ],
      "metadata": {
        "id": "GMA2cwWF_5Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2350,2380):\n",
        "  print(X_train_reshaped[i])\n",
        "  print(y_train_one_hot[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP2uyhFZVMWb",
        "outputId": "76bbfbf3-6bd9-48a4-926a-d750909fec50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9.019611  2.       16.       52.76      0.        0.        0.\n",
            "  -0.732422]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.00000e+00 -1.50000e+00  0.00000e+00  0.00000e+00  1.38968e+03\n",
            "   0.00000e+00  0.00000e+00 -4.88281e-01]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.00000e+00 -5.70000e+00  0.00000e+00  9.83000e+00  9.34440e+02\n",
            "   0.00000e+00  0.00000e+00 -2.44141e-01]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.00000e+00 -3.60000e+00 -1.00000e+00  0.00000e+00  1.79700e+03\n",
            "   0.00000e+00  0.00000e+00 -2.44141e-01]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[  0.       182.8       56.         8.11     359.4        0.\n",
            "    1.         9.033203]]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.        3.1      -3.       26.87      0.        0.        0.\n",
            "   0.732422]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.       47.3       0.        0.        0.        0.        0.\n",
            "  -0.244141]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 24.313734 -15.3       -3.        78.83       0.         0.\n",
            "    0.        -3.90625 ]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[28.235304  0.8       0.       69.47      0.        0.        0.\n",
            "   0.244141]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.   -1.3   0.   90.08  0.    0.    0.    0.  ]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.00000e+00  1.00000e-01  0.00000e+00  0.00000e+00  1.67720e+03\n",
            "   0.00000e+00  0.00000e+00 -2.44141e-01]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 14.509809  -3.8        0.       104.39       0.         0.\n",
            "    0.         0.      ]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 3.529413 -2.2      -1.        8.63      0.        0.        0.\n",
            "  -0.244141]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.       -9.        0.       45.08      0.        0.        0.\n",
            "  -1.708984]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.       -6.4       3.       12.77      0.        0.        0.\n",
            "  -0.488281]]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.00000e+00 -1.07000e+01  1.10000e+01  4.56000e+00  1.12612e+03\n",
            "   0.00000e+00  0.00000e+00 -4.88281e-01]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.00000e+00 -1.80000e+00  0.00000e+00  0.00000e+00  1.07820e+03\n",
            "   0.00000e+00  0.00000e+00 -2.44141e-01]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[   0.     -1.5     0.      3.8  1150.08    0.      0.      0.  ]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[18.823536  0.4       0.       20.48      0.        0.        0.\n",
            "   0.      ]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[  10.196082 -332.        345.          5.71        0.          0.\n",
            "     0.        -13.427734]]\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[0.0000000e+00 1.2160000e+02 8.7000000e+01 2.8200000e+01 1.9886800e+03\n",
            "  0.0000000e+00 1.0000000e+00 1.8310547e+01]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.   -1.3  -1.   26.51  0.    0.    0.    0.  ]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[  0.       -10.3        5.        47.55       0.         0.\n",
            "    0.        -1.953125]]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[20.000007 -7.7       0.       15.96      0.        0.        0.\n",
            "  -0.732422]]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.00000e+00 -4.20000e+00 -4.00000e+00  2.04300e+01  1.22196e+03\n",
            "   0.00000e+00  0.00000e+00 -7.32422e-01]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 27.058833 -28.9       30.        24.81       0.         0.\n",
            "    0.        -4.638672]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 0.00000e+00 -2.90000e+02  0.00000e+00  0.00000e+00  0.00000e+00\n",
            "   0.00000e+00  0.00000e+00 -2.44141e-01]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[ 20.784321 -11.4        7.        15.63       0.         0.\n",
            "    0.        -1.220703]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[23.921577  1.6       0.       42.92      0.        0.        0.\n",
            "   0.488281]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[17.647065  2.7       0.        8.26      0.        0.        0.\n",
            "  -0.488281]]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(256, input_shape=(1, 8)))  # 1 time step, 8 features\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer for 12 classes with softmax activation\n",
        "model.add(Dense(12, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train_one_hot,\n",
        "    validation_split=0.2,  # using 20% of the training data for validation\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    verbose=1,\n",
        "    callbacks=[reduce_lr, early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "Uq5whPHH_5-x",
        "outputId": "fd87605f-2786-486d-caf0-e377b89f3394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "44936/44936 [==============================] - 524s 12ms/step - loss: 0.3860 - accuracy: 0.8910 - val_loss: 0.3813 - val_accuracy: 0.8933 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "44936/44936 [==============================] - 477s 11ms/step - loss: 0.3702 - accuracy: 0.8929 - val_loss: 0.3730 - val_accuracy: 0.8931 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "27074/44936 [=================>............] - ETA: 2:55 - loss: 0.3655 - accuracy: 0.8937"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3edf2ea94bf1>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mX_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# using 20% of the training data for validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = Sequential()\n",
        "\n",
        "lstm_model.add(LSTM(256, input_shape=(1, 8)))  # 1 time step, 8 features\n",
        "\n",
        "lstm_model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer for 12 classes with softmax activation\n",
        "lstm_model.add(Dense(12, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "lstm_reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto')\n",
        "lstm_early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "lstm_history = lstm_model.fit(\n",
        "    X_train_reshaped, y_train_one_hot,\n",
        "    validation_split=0.2,  # using 20% of the training data for validation\n",
        "    epochs=15,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        "    callbacks=[lstm_reduce_lr, lstm_early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "N7RKTiSqqEko",
        "outputId": "64ba9b04-0e8b-4f2a-a2a1-c977ee676588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "11234/11234 [==============================] - 168s 15ms/step - loss: 0.3788 - accuracy: 0.8918 - val_loss: 0.3600 - val_accuracy: 0.8933 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "11234/11234 [==============================] - 174s 15ms/step - loss: 0.3583 - accuracy: 0.8943 - val_loss: 0.3571 - val_accuracy: 0.8950 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "11234/11234 [==============================] - 168s 15ms/step - loss: 0.3527 - accuracy: 0.8949 - val_loss: 0.3567 - val_accuracy: 0.8954 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "11234/11234 [==============================] - 168s 15ms/step - loss: 0.3516 - accuracy: 0.8955 - val_loss: 0.3563 - val_accuracy: 0.8962 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "11234/11234 [==============================] - 169s 15ms/step - loss: 0.3502 - accuracy: 0.8957 - val_loss: 0.3490 - val_accuracy: 0.8971 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "11234/11234 [==============================] - 166s 15ms/step - loss: 0.3478 - accuracy: 0.8961 - val_loss: 0.3496 - val_accuracy: 0.8968 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "11234/11234 [==============================] - 173s 15ms/step - loss: 0.3493 - accuracy: 0.8961 - val_loss: 0.3473 - val_accuracy: 0.8968 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "11234/11234 [==============================] - 170s 15ms/step - loss: 0.3462 - accuracy: 0.8964 - val_loss: 0.3485 - val_accuracy: 0.8969 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "11234/11234 [==============================] - 159s 14ms/step - loss: 0.3450 - accuracy: 0.8963 - val_loss: 0.3450 - val_accuracy: 0.8970 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "11234/11234 [==============================] - 151s 13ms/step - loss: 0.3441 - accuracy: 0.8966 - val_loss: 0.3452 - val_accuracy: 0.8970 - lr: 0.0010\n",
            "Epoch 11/15\n",
            " 3303/11234 [=======>......................] - ETA: 1:40 - loss: 0.3455 - accuracy: 0.8960"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-cb15b7b8448a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m lstm_history = lstm_model.fit(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mX_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# using 20% of the training data for validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_lstm_model = Sequential()\n",
        "\n",
        "# Add a Bidirectional LSTM layer\n",
        "bi_lstm_model.add(Bidirectional(LSTM(256), input_shape=(1, 8)))\n",
        "\n",
        "# Add a Dense layer with ReLU activation\n",
        "bi_lstm_model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer for 12 classes with softmax activation\n",
        "bi_lstm_model.add(Dense(12, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "bi_lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "# Train the model\n",
        "bi_lstm_history = model.fit(\n",
        "    X_train_reshaped, y_train_one_hot,\n",
        "    validation_split=0.2,  # using 20% of the training data for validation\n",
        "    epochs=15,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        "    callbacks=[reduce_lr, early_stop]\n",
        ")\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "#CSV Logger"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q6lEf2treJe",
        "outputId": "375d6322-5f64-4d02-b179-71f9f28bae5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "11234/11234 [==============================] - 168s 15ms/step - loss: 0.3663 - accuracy: 0.8933 - val_loss: 0.3537 - val_accuracy: 0.8943 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "11234/11234 [==============================] - 147s 13ms/step - loss: 0.3551 - accuracy: 0.8945 - val_loss: 0.3508 - val_accuracy: 0.8963 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "11234/11234 [==============================] - 161s 14ms/step - loss: 0.3519 - accuracy: 0.8952 - val_loss: 0.3552 - val_accuracy: 0.8960 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "11232/11234 [============================>.] - ETA: 0s - loss: 0.3512 - accuracy: 0.8955\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "11234/11234 [==============================] - 161s 14ms/step - loss: 0.3512 - accuracy: 0.8955 - val_loss: 0.3514 - val_accuracy: 0.8963 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "11234/11234 [==============================] - 159s 14ms/step - loss: 0.3380 - accuracy: 0.8977 - val_loss: 0.3384 - val_accuracy: 0.8984 - lr: 1.0000e-04\n",
            "Epoch 6/15\n",
            "11234/11234 [==============================] - 154s 14ms/step - loss: 0.3345 - accuracy: 0.8981 - val_loss: 0.3375 - val_accuracy: 0.8983 - lr: 1.0000e-04\n",
            "Epoch 7/15\n",
            "11234/11234 [==============================] - 155s 14ms/step - loss: 0.3330 - accuracy: 0.8982 - val_loss: 0.3361 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
            "Epoch 8/15\n",
            "11234/11234 [==============================] - 167s 15ms/step - loss: 0.3319 - accuracy: 0.8983 - val_loss: 0.3357 - val_accuracy: 0.8983 - lr: 1.0000e-04\n",
            "Epoch 9/15\n",
            "11234/11234 [==============================] - 164s 15ms/step - loss: 0.3311 - accuracy: 0.8985 - val_loss: 0.3351 - val_accuracy: 0.8983 - lr: 1.0000e-04\n",
            "Epoch 10/15\n",
            "11234/11234 [==============================] - 157s 14ms/step - loss: 0.3304 - accuracy: 0.8987 - val_loss: 0.3352 - val_accuracy: 0.8984 - lr: 1.0000e-04\n",
            "Epoch 11/15\n",
            "11234/11234 [==============================] - 162s 14ms/step - loss: 0.3297 - accuracy: 0.8987 - val_loss: 0.3350 - val_accuracy: 0.8985 - lr: 1.0000e-04\n",
            "Epoch 12/15\n",
            "11234/11234 [==============================] - 154s 14ms/step - loss: 0.3292 - accuracy: 0.8987 - val_loss: 0.3345 - val_accuracy: 0.8984 - lr: 1.0000e-04\n",
            "Epoch 13/15\n",
            "11234/11234 [==============================] - 153s 14ms/step - loss: 0.3287 - accuracy: 0.8989 - val_loss: 0.3341 - val_accuracy: 0.8986 - lr: 1.0000e-04\n",
            "Epoch 14/15\n",
            "11234/11234 [==============================] - 156s 14ms/step - loss: 0.3282 - accuracy: 0.8988 - val_loss: 0.3344 - val_accuracy: 0.8988 - lr: 1.0000e-04\n",
            "Epoch 15/15\n",
            "11232/11234 [============================>.] - ETA: 0s - loss: 0.3279 - accuracy: 0.8988\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "11234/11234 [==============================] - 164s 15ms/step - loss: 0.3279 - accuracy: 0.8988 - val_loss: 0.3341 - val_accuracy: 0.8986 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
      ],
      "metadata": {
        "id": "I9C_SweZ_4-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "# Predict the probabilities for the test data\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "# Stop the timer\n",
        "end_time = time.time()\n",
        "testing_time = end_time - start_time\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test_one_hot, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and f1-score\n",
        "test_loss, test_acc = model.evaluate(X_test_reshaped, y_test_one_hot)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_acc}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(f\"Testing Time: {testing_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs7C_vjh-WvM",
        "outputId": "7a373abd-e4c6-4d1d-a199-3d25ee758ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7022/7022 [==============================] - 32s 5ms/step\n",
            "7022/7022 [==============================] - 32s 4ms/step - loss: 0.3333 - accuracy: 0.8985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.33330613374710083\n",
            "Test Accuracy: 0.8985085487365723\n",
            "Precision: 0.8742026764686015\n",
            "Recall: 0.8985085388487576\n",
            "F1-Score: 0.875100517119682\n",
            "Testing Time: 35.0097918510437 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test, y_pred, target_names=[f\"Class {i}\" for i in range(12)])\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR1U5L2EA9yl",
        "outputId": "33893e19-8449-4972-c783-5abf972aa4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.91      0.98      0.95    195913\n",
            "     Class 1       0.59      0.15      0.24     13341\n",
            "     Class 2       0.76      0.61      0.68      5767\n",
            "     Class 3       0.78      0.62      0.69      5204\n",
            "     Class 4       0.58      0.15      0.23      1182\n",
            "     Class 5       0.62      0.14      0.22      1120\n",
            "     Class 6       0.30      0.05      0.08       454\n",
            "     Class 7       0.00      0.00      0.00       208\n",
            "     Class 8       0.00      0.00      0.00       559\n",
            "     Class 9       0.00      0.00      0.00       142\n",
            "    Class 10       0.00      0.00      0.00       302\n",
            "    Class 11       0.57      0.25      0.35       487\n",
            "\n",
            "    accuracy                           0.90    224679\n",
            "   macro avg       0.43      0.25      0.29    224679\n",
            "weighted avg       0.87      0.90      0.88    224679\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_lstm_model = Sequential()\n",
        "\n",
        "# Convolutional layer without max pooling\n",
        "cnn_lstm_model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, 1, 8)))\n",
        "cnn_lstm_model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "# LSTM layer\n",
        "cnn_lstm_model.add(LSTM(256))\n",
        "\n",
        "cnn_lstm_model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer for 12 classes with softmax activation\n",
        "cnn_lstm_model.add(Dense(12, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "cnn_lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "cnn_lstm_reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto')\n",
        "cnn_lstm_early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "cnn_lstm_history = cnn_lstm_model.fit(\n",
        "    X_train_reshaped, y_train_one_hot,\n",
        "    validation_split=0.2,\n",
        "    epochs=15,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        "    callbacks=[cnn_lstm_reduce_lr, cnn_lstm_early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "0ImX6Ni7syJ4",
        "outputId": "bae3fe43-0653-430e-b90e-f35198087fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_6\" is incompatible with the layer: expected shape=(None, None, 1, 8), found shape=(None, 1, 8)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f1896f9a75a2>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m cnn_lstm_history = cnn_lstm_model.fit(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mX_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_6\" is incompatible with the layer: expected shape=(None, None, 1, 8), found shape=(None, 1, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the training results\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cMjUshX6KgH-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}